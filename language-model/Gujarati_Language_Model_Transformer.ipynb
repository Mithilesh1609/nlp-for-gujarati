{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.1.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/gaurav/PycharmProjects/nlp-for-gujarati/language-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.tokenizer import GujaratiTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inltk.tokenizer.GujaratiTokenizer"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GujaratiTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GujaratiTokenizer(BaseTokenizer):\n",
    "#     def __init__(self, lang:str):\n",
    "#         self.lang = lang\n",
    "#         self.sp = spm.SentencePieceProcessor()\n",
    "#         self.sp.Load(str(path/\"../tokenizer/gujarati_lm.model\"))\n",
    "        \n",
    "#     def tokenizer(self, t:str) -> List[str]:\n",
    "#         return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/gujarati_lm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(20000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<s>',\n",
       " '</s>',\n",
       " '.',\n",
       " ',',\n",
       " '▁છે',\n",
       " '▁',\n",
       " '▁અને',\n",
       " 'ની',\n",
       " 'માં',\n",
       " 'ના',\n",
       " '▁આ',\n",
       " 'ને',\n",
       " '▁જ',\n",
       " '▁એક',\n",
       " '▁તેમ',\n",
       " '▁આવેલા',\n",
       " 'નો',\n",
       " 'નું',\n",
       " '▁કે',\n",
       " '▁ગામમાં',\n",
       " '▁ખેતી',\n",
       " '▁પણ',\n",
       " '▁માટે',\n",
       " 'થી',\n",
       " '▁આવે',\n",
       " '▁ભાગમાં',\n",
       " '▁કરવામાં',\n",
       " '▁તે',\n",
       " 'ો',\n",
       " 'ે',\n",
       " '▁q',\n",
       " '▁�',\n",
       " 'ી',\n",
       " '-',\n",
       " '▁ગામ',\n",
       " '▁પર',\n",
       " '▁હતી',\n",
       " '▁ભારત',\n",
       " '▁ગુજરાત',\n",
       " '▁મુખ્ય',\n",
       " '▁જે',\n",
       " 'X',\n",
       " '▁આવેલું',\n",
       " '▁હતા',\n",
       " '▁સ્થાન',\n",
       " 'એ',\n",
       " '▁એ',\n",
       " '▁હતો',\n",
       " '▁પશ્ચિમ',\n",
       " '▁ડેરી',\n",
       " '▁રાજ્યના',\n",
       " '▁દેશના',\n",
       " '▁ભારતમાં',\n",
       " '▁મુખ્યત્વે',\n",
       " '▁સાથે',\n",
       " '▁શાળા',\n",
       " '▁હતું',\n",
       " '▁જેવી',\n",
       " 'ં',\n",
       " '▁પ્રાથમિક',\n",
       " '▁કરી',\n",
       " '▁દૂધ',\n",
       " '▁અન્ય',\n",
       " '▁પશુપાલન',\n",
       " '▁ગામના',\n",
       " '▁હોય',\n",
       " '▁ખેતમજૂરી',\n",
       " '▁આંગણવાડી',\n",
       " '▁વ્યવસાય',\n",
       " '▁પંચાયતઘર',\n",
       " '�',\n",
       " '▁પ્રાપ્ય',\n",
       " '▁સવલતો',\n",
       " '▁તરીકે',\n",
       " '▁લોકોનો',\n",
       " '▁તાલુકામાં',\n",
       " 'ગુજરાત',\n",
       " '▁જિલ્લામાં',\n",
       " '▁પાક',\n",
       " '▁દ્વારા',\n",
       " '▁કરે',\n",
       " '▁થયેલી',\n",
       " 'ા',\n",
       " '▁શાકભાજીના',\n",
       " '▁કુલ',\n",
       " '▁એવા',\n",
       " '▁થાય',\n",
       " 'ક',\n",
       " '▁રીતે',\n",
       " 'ન',\n",
       " 'સ',\n",
       " '▁બાજરી',\n",
       " 'ર',\n",
       " '▁પૈકીના',\n",
       " '▁લોકો',\n",
       " '▁કપાસ',\n",
       " '▁તેઓ',\n",
       " '▁\"',\n",
       " '▁તાલુકાઓ',\n",
       " '▁તેના',\n",
       " 'નાં',\n",
       " '\"',\n",
       " 'લ',\n",
       " 'ઓ',\n",
       " '▁ઘઉં',\n",
       " '▁વધુ',\n",
       " '▁આવી',\n",
       " 's',\n",
       " '▁અથવા',\n",
       " '▁ના',\n",
       " 'મ',\n",
       " '▁ઉપયોગ',\n",
       " '▁તેને',\n",
       " '▁તેમણે',\n",
       " '▁સુધી',\n",
       " '▁નથી',\n",
       " '▁સૌથી',\n",
       " '▁બે',\n",
       " 'તા',\n",
       " '▁કરવા',\n",
       " '▁તેમના',\n",
       " '▁ન',\n",
       " '▁કારણે',\n",
       " ':',\n",
       " '▁the',\n",
       " '▁ઉત્તર',\n",
       " '▁શકે',\n",
       " '▁તેની',\n",
       " '▁રજકો',\n",
       " '્સ',\n",
       " '▁જીરુ',\n",
       " '▁પછી',\n",
       " 'માંથી',\n",
       " '▁માં',\n",
       " '▁તો',\n",
       " '▁જેમાં',\n",
       " '▁તથા',\n",
       " '▁જ્યારે',\n",
       " '▁મધ્ય',\n",
       " '▁અ',\n",
       " '▁દક્ષિણ',\n",
       " '▁કર્યો',\n",
       " '▁દિવેલા',\n",
       " '▁કરીને',\n",
       " '▁પરંતુ',\n",
       " '▁નામ',\n",
       " '▁બાદ',\n",
       " '▁પ્રથમ',\n",
       " '▁ખાતે',\n",
       " 'મી',\n",
       " '▁વિસ્તારમાં',\n",
       " '▁કર્યું',\n",
       " '▁આવ્યું',\n",
       " 'ત',\n",
       " '▁સમાવેશ',\n",
       " '▁કરતા',\n",
       " '▁વર્ષ',\n",
       " '▁થયો',\n",
       " '▁સામાન્ય',\n",
       " '▁‘',\n",
       " '▁થઈ',\n",
       " '▁મોટા',\n",
       " '▁ત્યારે',\n",
       " '▁કેટલાક',\n",
       " '▁ઉપરાંત',\n",
       " '▁શકાય',\n",
       " 'જ',\n",
       " '▁તેમજ',\n",
       " '▁તેમની',\n",
       " 'ડ',\n",
       " '▁અહીં',\n",
       " \"'\",\n",
       " 'િત',\n",
       " '▁આવ્યો',\n",
       " '▁of',\n",
       " '▁તેમને',\n",
       " 'મા',\n",
       " 'લા',\n",
       " '▁ડાંગર',\n",
       " '▁દરમિયાન',\n",
       " '▁ધરાવે',\n",
       " 'વા',\n",
       " '▁આવ્યા',\n",
       " '▁ભારતીય',\n",
       " '▁ભાગ',\n",
       " '▁સૌરાષ્ટ્ર',\n",
       " 'લી',\n",
       " '▁જિલ્લાના',\n",
       " '▁રોજ',\n",
       " '▁ખાસ',\n",
       " 'પ',\n",
       " 'આ',\n",
       " 'ળ',\n",
       " '▁પૂર્વ',\n",
       " '▁ઓફ',\n",
       " '▁જોવા',\n",
       " 'વ',\n",
       " '▁જેવા',\n",
       " '▁જો',\n",
       " '▁દિવસ',\n",
       " '’',\n",
       " '▁ને',\n",
       " '▁જેમ',\n",
       " '▁રહે',\n",
       " '▁મુજબ',\n",
       " 'જી',\n",
       " '▁વગેરે',\n",
       " '▁મંદિર',\n",
       " '▁તલ',\n",
       " 'રા',\n",
       " '▁પોતાના',\n",
       " '▁મગફળી',\n",
       " '▁મળે',\n",
       " 'ટ',\n",
       " '▁ચણા',\n",
       " 'ઝ',\n",
       " 'રી',\n",
       " 'ડી',\n",
       " '▁થઇ',\n",
       " '▁રાજ્ય',\n",
       " ';',\n",
       " '▁ધ',\n",
       " '▁and',\n",
       " '▁વચ્ચે',\n",
       " '▁એમ',\n",
       " '▁મકાઈ',\n",
       " '▁સમય',\n",
       " 'ણ',\n",
       " '▁થી',\n",
       " '▁તેમાં',\n",
       " '▁જાય',\n",
       " '▁કામ',\n",
       " 'ય',\n",
       " '▁વિવિધ',\n",
       " '▁તાલુકા',\n",
       " '▁સ',\n",
       " 'ડા',\n",
       " 'બ',\n",
       " '▁અલગ',\n",
       " '▁કોઈ',\n",
       " '▁વસ્તી',\n",
       " 'િક',\n",
       " '▁ઇ',\n",
       " '▁આવેલ',\n",
       " '▁દિવેલી',\n",
       " \"▁'\",\n",
       " '▁બી',\n",
       " '▁•',\n",
       " '▁ઘણા',\n",
       " '▁in',\n",
       " '▁સામે',\n",
       " '▁થયા',\n",
       " '▁ધરાવતા',\n",
       " 'ીય',\n",
       " '▁ત્રણ',\n",
       " '▁થયું',\n",
       " '▁શહેર',\n",
       " 'વી',\n",
       " '▁બીજા',\n",
       " 'ed',\n",
       " '▁તુવર',\n",
       " 'ું',\n",
       " '▁તેનો',\n",
       " '▁કરવાની',\n",
       " '▁ત્યાં',\n",
       " 'શ',\n",
       " '▁ઉપર',\n",
       " '▁નો',\n",
       " '▁બની',\n",
       " 'ુ',\n",
       " 'દ',\n",
       " 'ઇ',\n",
       " '▁પોતાની',\n",
       " '▁ની',\n",
       " '▁શરૂ',\n",
       " '▁વધારે',\n",
       " '▁આદિવાસી',\n",
       " '▁ઘણી',\n",
       " '▁કરતાં',\n",
       " 'ગ',\n",
       " '▁૬',\n",
       " '▁ફિલ્મ',\n",
       " '▁તરફ',\n",
       " '▁નદી',\n",
       " '▁ગુજરાતી',\n",
       " '▁માત્ર',\n",
       " '▁ઈ',\n",
       " '▁a',\n",
       " 'સી',\n",
       " 'તી',\n",
       " '▁છતાં',\n",
       " '▁આપવામાં',\n",
       " '્',\n",
       " '▁ભાષા',\n",
       " '▁કારણ',\n",
       " 'િયા',\n",
       " '/',\n",
       " '▁તેણે',\n",
       " 'કો',\n",
       " '▁હતાં',\n",
       " '▁ગયા',\n",
       " '▁શાકભાજી',\n",
       " 'િ',\n",
       " '▁વખત',\n",
       " '▁જન્મ',\n",
       " '▁દર',\n",
       " '▁ટકા',\n",
       " '▁કર્યા',\n",
       " '▁દરેક',\n",
       " '▁તમામ',\n",
       " '▁to',\n",
       " '▁સમયે',\n",
       " '▁આવેલી',\n",
       " '▁કોઇ',\n",
       " '▁લગભગ',\n",
       " '▁મે',\n",
       " '▁મળી',\n",
       " '▁ભારતના',\n",
       " 'કા',\n",
       " '▁તેનું',\n",
       " 'ચ',\n",
       " '▁હેઠળ',\n",
       " '▁દૂર',\n",
       " '▁રહી',\n",
       " '▁જોકે',\n",
       " '▁મેળવી',\n",
       " '▁વિસ્તાર',\n",
       " 'ંગ',\n",
       " '▁જેને',\n",
       " 'ઈ',\n",
       " '્યા',\n",
       " '▁૧૦',\n",
       " 'હ',\n",
       " 'પુર',\n",
       " '▁દેશ',\n",
       " '▁“',\n",
       " 'ોમાં',\n",
       " '▁જ્યાં',\n",
       " '▁હોવા',\n",
       " '▁પ્રમાણે',\n",
       " '▁વરિયાળી',\n",
       " '▁ખૂબ',\n",
       " '%',\n",
       " '▁વિ',\n",
       " '▁પાસે',\n",
       " '▁આપી',\n",
       " 'િંગ',\n",
       " 'રો',\n",
       " 'ટી',\n",
       " '▁શબ્દ',\n",
       " '▁રહ્યા',\n",
       " '▁મથક',\n",
       " '▁નજીક',\n",
       " '▁મૂળ',\n",
       " '▁મોટી',\n",
       " '▁ચાર',\n",
       " '▁યુદ્ધ',\n",
       " '▁પહેલા',\n",
       " '▁એટલે',\n",
       " '▁જાહેર',\n",
       " '▁રચના',\n",
       " '▁આપે',\n",
       " '▁બહાર',\n",
       " '▁નવા',\n",
       " '▁અભ્યાસ',\n",
       " '▁બંને',\n",
       " '▁અનેક',\n",
       " '▁-',\n",
       " '▁પાંચ',\n",
       " 'ોને',\n",
       " '▁યુ',\n",
       " 'યા',\n",
       " '▁પરથી',\n",
       " '▁આમ',\n",
       " '▁કંપની',\n",
       " '▁સેવા',\n",
       " '▁રાષ્ટ્રીય',\n",
       " 'સા',\n",
       " '▁અંગે',\n",
       " '▁વિકાસ',\n",
       " 'ફ',\n",
       " '▁૧૧',\n",
       " '▁શેરડી',\n",
       " '▁તમાકુ',\n",
       " 'મો',\n",
       " 'થ',\n",
       " '્યો',\n",
       " '▁જેવાં',\n",
       " '▁એવી',\n",
       " '▁અસર',\n",
       " '▁વિશ્વ',\n",
       " '▁લે',\n",
       " 'એસ',\n",
       " 'અ',\n",
       " '▁૯',\n",
       " '▁કહેવાય',\n",
       " '▁પાણી',\n",
       " 'તો',\n",
       " '▁નીચે',\n",
       " '▁સરકાર',\n",
       " 'કે',\n",
       " '▁જીવન',\n",
       " '▁ધર્મ',\n",
       " '2',\n",
       " '▁બંધ',\n",
       " '▁માર્ગ',\n",
       " '▁મૃત્યુ',\n",
       " '▁સુ',\n",
       " '▁જિલ્લો',\n",
       " '▁નહીં',\n",
       " '▁અનુસાર',\n",
       " '▁પ્રદેશ',\n",
       " 'ing',\n",
       " '▁ઉત્પાદન',\n",
       " '▁પડે',\n",
       " 'રે',\n",
       " '▁સ્થાપના',\n",
       " '▁સ્થળ',\n",
       " '▁રાજા',\n",
       " '▁પ્ર',\n",
       " 'ીયા',\n",
       " '▁મ',\n",
       " '▁દિશામાં',\n",
       " '▁કાર્ય',\n",
       " '▁બનાવવામાં',\n",
       " '▁એવું',\n",
       " '▁ઉપલબ્ધ',\n",
       " '▁હોવાથી',\n",
       " '▁પાન',\n",
       " '▁નાના',\n",
       " '”',\n",
       " '▁પ',\n",
       " '▁કા',\n",
       " '▁મા',\n",
       " 'ખ',\n",
       " '▁દિવસે',\n",
       " 'બી',\n",
       " '▁લેવામાં',\n",
       " '▁કહે',\n",
       " '▁સમગ્ર',\n",
       " '▁વસે',\n",
       " '▁વ',\n",
       " '▁કેટલીક',\n",
       " '▁આધારિત',\n",
       " '▁માહિતી',\n",
       " '▁શ્રી',\n",
       " 'ાઈ',\n",
       " '▁કેન્દ્ર',\n",
       " '▁શરૂઆત',\n",
       " '▁અમુક',\n",
       " '▁આગળ',\n",
       " 'પી',\n",
       " '▁પ્રકારના',\n",
       " '▁વ્યક્તિ',\n",
       " 'પર',\n",
       " '▁૧૪',\n",
       " '▁અર્થ',\n",
       " '▁સુરત',\n",
       " '▁કેળાં',\n",
       " 'ધ',\n",
       " '▁શિક્ષણ',\n",
       " '▁૮',\n",
       " '▁મદદ',\n",
       " '▁લેખ',\n",
       " '▁18',\n",
       " '▁છ',\n",
       " '▁યુનાઇટેડ',\n",
       " '▁સમયમાં',\n",
       " '▁પ્રાચીન',\n",
       " '▁રાજ',\n",
       " 'y',\n",
       " 'વે',\n",
       " '▁પ્રાપ્ત',\n",
       " '▁કો',\n",
       " 'પુરા',\n",
       " '▁૧',\n",
       " '▁મગ',\n",
       " '▁તેવી',\n",
       " '▁ઓ',\n",
       " '▁આવતા',\n",
       " 'લે',\n",
       " '▁પ્રમાણમાં',\n",
       " '▁સગવડ',\n",
       " '▁નગર',\n",
       " '▁તેવા',\n",
       " '▁કિ',\n",
       " '▁જુવાર',\n",
       " '▁is',\n",
       " 'd',\n",
       " '▁પહેલાં',\n",
       " 'ીંગ',\n",
       " '્ય',\n",
       " '▁જમીન',\n",
       " '▁ભગવાન',\n",
       " '▁૫',\n",
       " '▁સમાન',\n",
       " 'દા',\n",
       " '▁ક',\n",
       " '▁હવે',\n",
       " '▁સ્થાનિક',\n",
       " '▁ક્ષેત્ર',\n",
       " '▁મહત્વ',\n",
       " 'બા',\n",
       " '▁બીજી',\n",
       " '▁જિલ્લાનું',\n",
       " '▁દેવ',\n",
       " 'લો',\n",
       " '▁નિર્માણ',\n",
       " 'દુધની',\n",
       " '▁પૈકી',\n",
       " 'નુ',\n",
       " '▁કચ્છ',\n",
       " '▁ત્યાર',\n",
       " '▁ખેત',\n",
       " '▁સે',\n",
       " '▁બ',\n",
       " '▁આશરે',\n",
       " '▁નોકરી',\n",
       " '▁લોકોની',\n",
       " '▁અત્યંત',\n",
       " '▁વખતે',\n",
       " '▁1',\n",
       " '▁૭',\n",
       " '▁આધુનિક',\n",
       " 'વો',\n",
       " '▁એન્ડ',\n",
       " '▁૪',\n",
       " '▁રજૂ',\n",
       " '▁વધારો',\n",
       " '▁કાર્યો',\n",
       " '▁ઓછા',\n",
       " '▁પોતાનું',\n",
       " '▁પ્રદેશમાં',\n",
       " '▁શક્કરીયાં',\n",
       " '▁ચોક્કસ',\n",
       " '▁પ્રક્રિયા',\n",
       " '્યુ',\n",
       " '▁શોધ',\n",
       " '▁હિંદુ',\n",
       " '▁જંગલ',\n",
       " '▁વડે',\n",
       " '▁જેના',\n",
       " '▁જરૂર',\n",
       " '▁થતો',\n",
       " 'ોની',\n",
       " '▁બનાવવા',\n",
       " 'સ્',\n",
       " '▁તેથી',\n",
       " 'n',\n",
       " 'તે',\n",
       " '▁મહારાષ્ટ્ર',\n",
       " '▁રાજ્યમાં',\n",
       " '▁રંગ',\n",
       " '▁તૈયાર',\n",
       " '▁યોગ્ય',\n",
       " '▁૧૮',\n",
       " 'વામાં',\n",
       " '▁અમદાવાદ',\n",
       " '▁નવી',\n",
       " '▁માનવ',\n",
       " 'e',\n",
       " '▁બટાટા',\n",
       " 'er',\n",
       " 'ાઇ',\n",
       " '▁પદ્ધતિ',\n",
       " 'ન્ટ',\n",
       " '▁હાથ',\n",
       " 'જે',\n",
       " '▁અંત',\n",
       " '▁સી',\n",
       " '▁સંગીત',\n",
       " '▁ડુંગરા',\n",
       " '▁ઉ',\n",
       " '▁ચાલુ',\n",
       " 'સર',\n",
       " '▁પ્રકારની',\n",
       " '▁આપ્યો',\n",
       " '▁સાહિત્ય',\n",
       " '▁રહ્યો',\n",
       " '▁અંગ્રેજી',\n",
       " '▁ચા',\n",
       " '▁ગયો',\n",
       " 'ર્સ',\n",
       " 'સે',\n",
       " '▁ઓછી',\n",
       " '▁કર',\n",
       " 'વર',\n",
       " '▁વિશાળ',\n",
       " 'કી',\n",
       " '▁બ્રિટિશ',\n",
       " 'વિ',\n",
       " 'ોના',\n",
       " '▁ઓળખાય',\n",
       " '્યું',\n",
       " '▁દરમ્યાન',\n",
       " '▁બનાસકાંઠા',\n",
       " '▁માનવામાં',\n",
       " '▁પુત્ર',\n",
       " '▁બન્યા',\n",
       " '▁સુધારો',\n",
       " 't',\n",
       " '▁આંતરરાષ્ટ્રીય',\n",
       " '▁વડોદરા',\n",
       " '▁જેથી',\n",
       " '▁ભૂમિકા',\n",
       " '▁સંખ્યા',\n",
       " '▁લોકપ્રિય',\n",
       " '▁આદિવાસીઓ',\n",
       " '▁વાત',\n",
       " 'C',\n",
       " '▁હોવાનું',\n",
       " '▁પી',\n",
       " 'વાળા',\n",
       " '▁આવેલો',\n",
       " '▁વસવાટ',\n",
       " 'ડો',\n",
       " 'જા',\n",
       " 'કાર',\n",
       " 'ોએ',\n",
       " '▁The',\n",
       " '▁પૂરી',\n",
       " '▁ફરી',\n",
       " '▁સૈનિકો',\n",
       " '▁ઘણાં',\n",
       " '▁ડી',\n",
       " '▁આપ્યું',\n",
       " '▁વ્યવસાયમાં',\n",
       " 'ણી',\n",
       " '▁પિતા',\n",
       " '▁ભાવનગર',\n",
       " '▁બધા',\n",
       " '▁કહેવા',\n",
       " '’,',\n",
       " '▁રહ્યું',\n",
       " 'al',\n",
       " '▁ઉલ્લેખ',\n",
       " '▁બને',\n",
       " 'ખા',\n",
       " '▁થતા',\n",
       " 'કર',\n",
       " '▁સિ',\n",
       " '▁2',\n",
       " '▁ઉદાહરણ',\n",
       " 'ન્સ',\n",
       " '▁બોલી',\n",
       " 'વું',\n",
       " '▁શાસન',\n",
       " '▁બિન',\n",
       " '▁કી',\n",
       " '▁એવો',\n",
       " '▁રે',\n",
       " '▁2007',\n",
       " '▁રોગ',\n",
       " '▁થયેલ',\n",
       " '▁અહીંના',\n",
       " '▁સિવાય',\n",
       " '▁10',\n",
       " '▁હાલમાં',\n",
       " '▁નિ',\n",
       " '▁કરતી',\n",
       " 'યુ',\n",
       " '▁ત્યારબાદ',\n",
       " 'ટા',\n",
       " '▁વ્યવસ્થા',\n",
       " '▁રહેલા',\n",
       " '▁તેમનો',\n",
       " '▁2008',\n",
       " '▁સુધીમાં',\n",
       " '1',\n",
       " '▁વાર',\n",
       " '▁થયેલા',\n",
       " '▁૨',\n",
       " 'ક્સ',\n",
       " '▁પાડે',\n",
       " '▁વર્ષના',\n",
       " '▁બાળકો',\n",
       " '▁લગ્ન',\n",
       " '▁નક્કી',\n",
       " '▁20',\n",
       " '▁થતી',\n",
       " '▁પૂર્ણ',\n",
       " '▁લાંબા',\n",
       " 'ઓને',\n",
       " '▁દિલ્હી',\n",
       " '▁બહુ',\n",
       " '▁ધ્યાન',\n",
       " '▁માતા',\n",
       " '▁ધરાવતી',\n",
       " '▁ઉચ્ચ',\n",
       " '▁આજે',\n",
       " '▁શહેરમાં',\n",
       " '▁હ',\n",
       " 'es',\n",
       " 'ેલા',\n",
       " 'ly',\n",
       " '▁ભાગના',\n",
       " '▁સત્તા',\n",
       " '▁ઓળખવા',\n",
       " '▁જાણીતા',\n",
       " '▁રામ',\n",
       " 'ીક',\n",
       " '▁as',\n",
       " '▁મોટો',\n",
       " '▁ઘર',\n",
       " '▁૩',\n",
       " '▁કહ્યું',\n",
       " '°',\n",
       " '▁કલા',\n",
       " '▁3',\n",
       " '▁આર્થિક',\n",
       " '▁લેવા',\n",
       " '▁પડી',\n",
       " '▁સ્વરૂપ',\n",
       " 'નિ',\n",
       " 'ઉ',\n",
       " '▁આવતી',\n",
       " '▁મુંબઈ',\n",
       " '▁પ્રમાણ',\n",
       " '▁દા',\n",
       " '▁પસાર',\n",
       " '▁જણાવ્યું',\n",
       " '▁અમેરિકન',\n",
       " '▁અંદર',\n",
       " 'મે',\n",
       " '▁સ્થિત',\n",
       " '▁ક્ષમતા',\n",
       " '▁સાત',\n",
       " '▁દે',\n",
       " '▁સ્તર',\n",
       " '▁પિયત',\n",
       " '▁સતત',\n",
       " '▁ગો',\n",
       " '▁કરવાનો',\n",
       " 'o',\n",
       " '▁જેટલા',\n",
       " '▁સંપૂર્ણ',\n",
       " '▁વર્ષે',\n",
       " 'તિ',\n",
       " '▁જેટલી',\n",
       " '▁યોજના',\n",
       " '▁જરૂરી',\n",
       " '▁લીધે',\n",
       " 'શે',\n",
       " '▁મહા',\n",
       " '▁લા',\n",
       " 'સ્ટ',\n",
       " 'ૂ',\n",
       " '▁હે',\n",
       " '▁ઉપ',\n",
       " 'r',\n",
       " 'યો',\n",
       " 'ઠી',\n",
       " '▁રાજકીય',\n",
       " 'ણા',\n",
       " '▁નેટવર્ક',\n",
       " '▁સંશોધન',\n",
       " '▁પૃથ્વી',\n",
       " '▁ભાગે',\n",
       " '▁વર્ષની',\n",
       " '▁ધાર્મિક',\n",
       " '▁ક્રિકેટ',\n",
       " '4',\n",
       " '▁સં',\n",
       " '▁ત',\n",
       " 'ભ',\n",
       " '▁વિચાર',\n",
       " '▁લઈ',\n",
       " '▁ગ',\n",
       " '▁આપવા',\n",
       " '▁પ્રખ્યાત',\n",
       " '▁નોંધપાત્ર',\n",
       " 'ીઓ',\n",
       " '▁15',\n",
       " '▁દેશોમાં',\n",
       " '▁જેઓ',\n",
       " '▁સામાજિક',\n",
       " 'લિ',\n",
       " '▁16',\n",
       " '▁નામે',\n",
       " '▁વિશે',\n",
       " '▁17',\n",
       " '▁મોટું',\n",
       " '▁નામના',\n",
       " '▁આસપાસ',\n",
       " '▁ગયું',\n",
       " '▁પ્રસિદ્ધ',\n",
       " 'ઘ',\n",
       " '▁સ્ટેટ્સ',\n",
       " 'ઓમાં',\n",
       " '▁સપાટી',\n",
       " '▁જાન્યુઆરી',\n",
       " '▁સૂર્ય',\n",
       " 'p',\n",
       " '▁સર',\n",
       " '▁મુ',\n",
       " '▁જાહેરાત',\n",
       " '▁શ્રેષ્ઠ',\n",
       " '▁નાની',\n",
       " '▁સદી',\n",
       " '▁બનાવી',\n",
       " '▁રાજકોટ',\n",
       " '▁આપ',\n",
       " 'ેલી',\n",
       " 'દાર',\n",
       " 'વાદ',\n",
       " '▁થોડા',\n",
       " '▁રાખવામાં',\n",
       " '▁અરવલ્લી',\n",
       " 'ડે',\n",
       " '▁સો',\n",
       " 'ીત',\n",
       " '▁વે',\n",
       " '▁કામગીરી',\n",
       " '▁રસ',\n",
       " '▁યુનિવર્સિટી',\n",
       " '▁પુરસ્કાર',\n",
       " '▁છોટાઉદેપુર',\n",
       " '▁પ્રમુખ',\n",
       " '▁જેનો',\n",
       " '▁રિ',\n",
       " 'િસ',\n",
       " '▁આધાર',\n",
       " '▁ફક્ત',\n",
       " '▁ફુલ',\n",
       " '▁સફળ',\n",
       " '▁પ્રવેશ',\n",
       " '▁સ્ટેશન',\n",
       " '▁s',\n",
       " '▁લોકોને',\n",
       " '▁થવા',\n",
       " '▁ઇતિહાસ',\n",
       " '▁2009',\n",
       " '▁લીધો',\n",
       " '▁4',\n",
       " '▁મિ',\n",
       " '.\"',\n",
       " 'વાડા',\n",
       " '▁જોઇએ',\n",
       " '▁વી',\n",
       " '▁બા',\n",
       " '▁પુસ્તક',\n",
       " 'મ્',\n",
       " '▁જ્ઞાન',\n",
       " '▁સમાજ',\n",
       " '▁વર્ષો',\n",
       " 'મિ',\n",
       " '▁મીટર',\n",
       " 'પા',\n",
       " '▁ડિ',\n",
       " 'દી',\n",
       " '▁કાર',\n",
       " '▁વિભાગ',\n",
       " '▁પ્રેમ',\n",
       " '▁પ્રતિ',\n",
       " '▁S',\n",
       " '▁લાલ',\n",
       " 'ગો',\n",
       " '▁આધારે',\n",
       " 'in',\n",
       " ')',\n",
       " 'ર્',\n",
       " '▁કરવાનું',\n",
       " '▁રમત',\n",
       " '▁કમ્પ્યુટર',\n",
       " '▁જતા',\n",
       " 'a',\n",
       " '▁નવ',\n",
       " '▁લીધી',\n",
       " 'b',\n",
       " '▁આવા',\n",
       " '▁અગાઉ',\n",
       " '▁રેલ્વે',\n",
       " '▁ભારે',\n",
       " '▁સ્થિતિ',\n",
       " '▁સંયુક્ત',\n",
       " '▁સદીના',\n",
       " '▁તળાવ',\n",
       " '▁સંસ્થા',\n",
       " '▁સભ્ય',\n",
       " '▁ડે',\n",
       " '▁એપ્રિલ',\n",
       " '▁પાછળ',\n",
       " '▁સંસ્કૃતિ',\n",
       " '▁ટીમ',\n",
       " '્ડ',\n",
       " '▁કાયદા',\n",
       " '▁દબાણ',\n",
       " '▁સંગ્રહ',\n",
       " 'ેશ્વર',\n",
       " 'બે',\n",
       " 'ાં',\n",
       " '▁કુ',\n",
       " '▁સ્',\n",
       " 'ેશન',\n",
       " '▁૧૨',\n",
       " '▁બદલે',\n",
       " '▁મહ',\n",
       " '▁પરંપરાગત',\n",
       " '▁જોઈએ',\n",
       " 'માન',\n",
       " '▁શિવ',\n",
       " 'રુ',\n",
       " '▁for',\n",
       " '▁વસતી',\n",
       " 'તું',\n",
       " '▁ચીન',\n",
       " '▁મી',\n",
       " '▁ધી',\n",
       " '▁કૃષ્ણ',\n",
       " '▁લાગે',\n",
       " '▁વર્ણન',\n",
       " '▁ઐતિહાસિક',\n",
       " '▁રાજધાની',\n",
       " '▁કાઢી',\n",
       " '▁લો',\n",
       " '▁દર્શાવે',\n",
       " '▁એમણે',\n",
       " '▁સદીમાં',\n",
       " '▁આયોજન',\n",
       " '▁સપ્ટેમ્બર',\n",
       " '▁પ્રભાવ',\n",
       " '▁:',\n",
       " 'ઠ',\n",
       " '▁શરીર',\n",
       " '▁સામેલ',\n",
       " '▁સારી',\n",
       " '▁મિલિયન',\n",
       " '▁ગણવા',\n",
       " '▁ચલાવે',\n",
       " '▁રા',\n",
       " '▁જૈન',\n",
       " '▁૧૫',\n",
       " 'ાય',\n",
       " '▁સંબંધ',\n",
       " '▁કેરી',\n",
       " '▁સંવત',\n",
       " '▁દેશો',\n",
       " '▁લ',\n",
       " '▁છોડ',\n",
       " '▁ખર્ચ',\n",
       " '▁વર્લ્ડ',\n",
       " '3',\n",
       " '૨',\n",
       " '▁નર્મદા',\n",
       " '▁by',\n",
       " '▁લોક',\n",
       " '▁વેચાણ',\n",
       " '▁A',\n",
       " '▁સમુદ્ર',\n",
       " '▁મેળવવા',\n",
       " '▁કિમી',\n",
       " '▁ઘટાડો',\n",
       " '▁જળ',\n",
       " '▁સંઘ',\n",
       " '▁સા',\n",
       " '▁જિલ્લાઓ',\n",
       " '6',\n",
       " '▁વિશેષ',\n",
       " '▁લશ્કરી',\n",
       " 'સો',\n",
       " '▁ડોલર',\n",
       " '▁લિ',\n",
       " '▁પાસેથી',\n",
       " '▁બન્યું',\n",
       " 'પ્ર',\n",
       " '▁વૈશ્વિક',\n",
       " 'ઃ',\n",
       " '▁પ્રકાશિત',\n",
       " '▁ડિસેમ્બર',\n",
       " '▁વિજય',\n",
       " '▁પ્રકાર',\n",
       " '▁વિશ્વમાં',\n",
       " '▁2006',\n",
       " '▁શબ્દો',\n",
       " '▁રીત',\n",
       " '▁સંચાલન',\n",
       " '▁)',\n",
       " '▁જૂન',\n",
       " '▁નવેમ્બર',\n",
       " 'તર',\n",
       " 'રિ',\n",
       " 'ન્',\n",
       " '▁શ્રેણી',\n",
       " '▁that',\n",
       " 'પણે',\n",
       " '▁ફેરફાર',\n",
       " '▁માર્ચ',\n",
       " '▁પરિણામે',\n",
       " '▁સૈન્ય',\n",
       " '▁વેપાર',\n",
       " '▁તાપમાન',\n",
       " '▁અડદ',\n",
       " '▁જીવ',\n",
       " '▁લાખ',\n",
       " 'ચા',\n",
       " '▁પ્રકાશ',\n",
       " 'શી',\n",
       " '▁વર્ષમાં',\n",
       " '▁અંતરે',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20,000 is the vocab size that we chose in sentencepiece\n",
    "gujarati_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tok_func=GujaratiTokenizer, lang='gu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_folder(path=path/'transformer', tokenizer=tokenizer, vocab=gujarati_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁મુખ્યત્વે ▁મકાઈ , ▁બાજરી , ▁કપાસ , ▁દિવેલી , ▁તમાકુ , ▁બટાટા , ▁શક્કરીયાં ▁તેમ ▁જ ▁અન્ય ▁શાકભાજીના ▁પાક ની ▁ખેતી ▁કરવામાં ▁આવે ▁છે . ▁આ ▁ગામમાં ▁પ્રાથમિક ▁શાળા , ▁પંચાયતઘર , ▁આંગણવાડી ▁તેમ ▁જ ▁દૂધ ની ▁ડેરી ▁જેવી ▁સવલતો ▁પ્રાપ્ય ▁થયેલી ▁છે . ▁x x bo s ▁હોલ ો ▁એ ▁આપણા ▁ગુજરાત ▁સહિત ▁દેશના ▁મોટા ▁ભાગમાં ▁જોવા ▁મળતું ▁ઘરઆંગણ ા નું ▁કપોત ▁કુળ નું ▁પક્ષી ▁છે . ▁તેની ▁ચાર</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>૨૭ , ૭ ૨૭ ▁હતી ▁જે ▁પૈકીના ં ▁૨૨ . ૪૦ % ▁લોકો ▁શહેરી ▁વિસ્તારમાં ▁વસવાટ ▁કરે ▁છે . ▁x x bo s ▁ગુજરાત ▁અને ▁ભારતમાં ▁સ્થાન ▁દૂધ ની ▁ડેરી ▁ચણા , ▁કપાસ , ▁દિવેલા , ▁રજકો ▁તેમજ ▁શાકભાજી ▁સરસ ીયા ▁ભારત ▁દેશના ▁પશ્ચિમ ▁ભાગમાં ▁આવેલા ▁ગુજરાત ▁રાજ્યના ▁સૌરાષ્ટ્ર ▁વિસ્તારમાં ▁આવેલા ▁અમરેલી ▁જિલ્લામાં ▁આવેલા ▁કુલ ▁૧૧ ▁તાલુકાઓ ▁પૈકીના ▁એક ▁એવા ▁ધારી ▁તાલુકામાં ▁આવેલું ▁એક ▁ગામ ▁છે . ▁સરસ ીયા ▁ગામના</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁આવેલા ▁મહ ીસાગર ▁જિલ્લામાં ▁આવેલા ▁લુણાવાડા ▁તાલુકા નું ▁એક ▁ગામ ▁છે . ▁કાં ક લીયા ▁ગામના ▁લોકોનો ▁મુખ્ય ▁વ્યવસાય ▁ખેતી , ▁ખેતમજૂરી ▁તેમ ▁જ ▁પશુપાલન ▁છે . ▁આ ▁ગામમાં ▁મુખ્યત્વે ▁મકાઈ , ▁બાજરી , ▁તુવર ▁તેમ ▁જ ▁શાકભાજીના ▁પાક ની ▁ખેતી ▁કરવામાં ▁આવે ▁છે . ▁આ ▁ગામમાં ▁પ્રાથમિક ▁શાળા , ▁પંચાયતઘર , ▁આંગણવાડી ▁તેમ ▁જ ▁દૂધ ની ▁ડેરી ▁જેવી ▁સવલતો ▁પ્રાપ્ય ▁થયેલી ▁છે . ▁x x bo s ▁ગુજરાત ▁અને</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁વેલેન્ટાઇન ▁પોસ્ટ કાર્ડ ▁અંદાજે ▁1900 થી ▁1910 ▁નાની ▁2 ▁ઇંચ ની ▁પોપ - અપ ▁વેલેન્ટાઇન ▁શુભેચ્છા ▁પત્રિકા ▁અંદાજે ▁1920 ▁ફૂટબોલ ▁રમી ▁રહેલો ▁ડિઝની ▁જેવો ▁દેખાતો ▁ઉંદર ડો ▁અને ▁બુલ ડો ગ ▁જાતિના ▁કૂતરા ને ▁જમણી ▁બાજુએ ▁મૂકે લા ▁પુલ ▁ટેબ ▁મારફતે ▁ગતિ ▁આપવામાં ▁આવી ▁છે , ▁અંદાજે ▁1920 ▁પત્રિકા ની ▁મધ્યમાં ▁વીજ પ્રતિ રોધક ▁સ ળ િયો ▁રાખવામાં ▁આવ્યો ▁છે ▁જેના ▁કારણે ▁કૂતરા ની ▁આંખ ની ▁કી કી ઓ ▁બંને</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁સાથે ▁ખરાબ ▁પરિસ્થિતિ ▁માં ▁શરૂ ▁થયો . ▁14 ▁ડિસેમ્બર ▁1962 ▁ના ▁તેમના ▁10 9 - દિવસીય ▁કક્ષ ીય ▁સ્થળાંતર ▁સાથે ▁જ ▁તે ▁શુક્ર ▁ની ▁ધરતી ▁થી ▁34 , 88 3 ▁કિમી ▁ઉપર ▁થી ▁પસાર ▁થવા ▁વાર ો ▁દુનિયા ▁નો ▁પ્રથમ ▁સફળ ▁આંતર ગ્રહ ીય ▁મિશન ▁બની ▁ગયો . ▁આ ▁ના ▁માઈક્રો વે વ ▁અને ▁ઇન્ફ્રારેડ ▁રેડિયો મીટર ▁થી ▁ખબર ▁પડી ▁કે ▁શુક્ર ▁ના ▁સૌથી ▁ઉપરી ▁વાદળ ▁શાંત ▁હતા ▁જ્યારે ▁પૂર્વ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, TransformerXL, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): TransformerXL(\n",
       "    (encoder): Embedding(20000, 410)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop_emb): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=410, out_features=20000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.482743</td>\n",
       "      <td>5.258771</td>\n",
       "      <td>0.302123</td>\n",
       "      <td>10:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.634204</td>\n",
       "      <td>4.804011</td>\n",
       "      <td>0.332904</td>\n",
       "      <td>10:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.389263</td>\n",
       "      <td>4.470369</td>\n",
       "      <td>0.351169</td>\n",
       "      <td>10:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.311111</td>\n",
       "      <td>4.236722</td>\n",
       "      <td>0.366975</td>\n",
       "      <td>10:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.973635</td>\n",
       "      <td>4.110125</td>\n",
       "      <td>0.374593</td>\n",
       "      <td>10:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.930423</td>\n",
       "      <td>4.043270</td>\n",
       "      <td>0.381622</td>\n",
       "      <td>10:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.844898</td>\n",
       "      <td>3.945026</td>\n",
       "      <td>0.387515</td>\n",
       "      <td>10:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.791715</td>\n",
       "      <td>3.871594</td>\n",
       "      <td>0.393068</td>\n",
       "      <td>10:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.655746</td>\n",
       "      <td>3.812247</td>\n",
       "      <td>0.399462</td>\n",
       "      <td>10:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.624314</td>\n",
       "      <td>3.724213</td>\n",
       "      <td>0.407831</td>\n",
       "      <td>10:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.468755</td>\n",
       "      <td>3.658032</td>\n",
       "      <td>0.415729</td>\n",
       "      <td>10:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.468830</td>\n",
       "      <td>3.589293</td>\n",
       "      <td>0.423519</td>\n",
       "      <td>10:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.295588</td>\n",
       "      <td>3.523212</td>\n",
       "      <td>0.432359</td>\n",
       "      <td>10:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.199539</td>\n",
       "      <td>3.472873</td>\n",
       "      <td>0.439117</td>\n",
       "      <td>10:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.198225</td>\n",
       "      <td>3.418880</td>\n",
       "      <td>0.446792</td>\n",
       "      <td>10:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.235161</td>\n",
       "      <td>3.381967</td>\n",
       "      <td>0.451972</td>\n",
       "      <td>10:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.041239</td>\n",
       "      <td>3.360283</td>\n",
       "      <td>0.456181</td>\n",
       "      <td>10:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.846339</td>\n",
       "      <td>3.343966</td>\n",
       "      <td>0.458738</td>\n",
       "      <td>10:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.815262</td>\n",
       "      <td>3.338327</td>\n",
       "      <td>0.459781</td>\n",
       "      <td>10:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.720052</td>\n",
       "      <td>3.336792</td>\n",
       "      <td>0.460034</td>\n",
       "      <td>10:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.30212295055389404.\n",
      "Better model found at epoch 1 with accuracy value: 0.3329038918018341.\n",
      "Better model found at epoch 2 with accuracy value: 0.35116884112358093.\n",
      "Better model found at epoch 3 with accuracy value: 0.36697545647621155.\n",
      "Better model found at epoch 4 with accuracy value: 0.3745930790901184.\n",
      "Better model found at epoch 5 with accuracy value: 0.38162174820899963.\n",
      "Better model found at epoch 6 with accuracy value: 0.38751542568206787.\n",
      "Better model found at epoch 7 with accuracy value: 0.3930676579475403.\n",
      "Better model found at epoch 8 with accuracy value: 0.39946219325065613.\n",
      "Better model found at epoch 9 with accuracy value: 0.4078311026096344.\n",
      "Better model found at epoch 10 with accuracy value: 0.4157285690307617.\n",
      "Better model found at epoch 11 with accuracy value: 0.42351892590522766.\n",
      "Better model found at epoch 12 with accuracy value: 0.4323589503765106.\n",
      "Better model found at epoch 13 with accuracy value: 0.43911659717559814.\n",
      "Better model found at epoch 14 with accuracy value: 0.4467921257019043.\n",
      "Better model found at epoch 15 with accuracy value: 0.45197197794914246.\n",
      "Better model found at epoch 16 with accuracy value: 0.45618051290512085.\n",
      "Better model found at epoch 17 with accuracy value: 0.45873820781707764.\n",
      "Better model found at epoch 18 with accuracy value: 0.4597812592983246.\n",
      "Better model found at epoch 19 with accuracy value: 0.46003445982933044.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 1e-3, moms=(0.8,0.7), callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"ગુજરાત\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ગુજરાત ▁અને ▁ભારતમાં ▁સ્થાન ▁કે ળ ▁ભારત ▁દેશના ▁પશ્ચિમ ▁ભાગમાં ▁આવેલા ▁ગુજરાત ▁રાજ્યના ▁ઉત્તર ▁ભાગમાં ▁આવેલા ▁બનાસકાંઠા ▁જિલ્લામાં ▁આવેલા ▁કુલ ▁૧૪ ▁તાલુકાઓ ▁પૈકીના ▁એક ▁એવા ▁ધાનેરા ▁તાલુકામાં ▁આવેલું ▁એક ▁ગામ ▁છે . ▁કે ળ ▁ગામના ▁લોકોનો ▁મુખ્ય ▁વ્યવસાય ▁ખેતી , ▁ખેતમજૂરી\n",
      "ગુજરાત ▁અને ▁ભારતમાં ▁સ્થાન ▁દૂધ ની ▁ડેરી ▁ચણા , ▁કપાસ , ▁દિવેલા , ▁રજકો ▁તેમજ ▁શાકભાજી ▁કોઠા ડીયા ▁ભારત ▁દેશના ▁પશ્ચિમ ▁ભાગમાં ▁આવેલા ▁ગુજરાત ▁રાજ્યના ▁સૌરાષ્ટ્ર ▁વિસ્તારમાં ▁આવેલા ▁અમરેલી ▁જિલ્લામાં ▁આવેલા ▁કુલ ▁૧૧ ▁તાલુકાઓ ▁પૈકીના ▁એક ▁એવા ▁ખાંભા ▁તાલુકામાં ▁આવેલું ▁એક\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.12874479703069"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.336792)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "learn.model.eval()\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating embedding vectors for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-gujarati/language-model')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner(path / 'GujaratiDataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_model(learn.model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20000, 410])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.state_dict()['encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 410)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('embeddings_transformer.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.219362</td>\n",
       "      <td>0.169356</td>\n",
       "      <td>-0.325940</td>\n",
       "      <td>0.139796</td>\n",
       "      <td>0.186205</td>\n",
       "      <td>-0.171053</td>\n",
       "      <td>0.021949</td>\n",
       "      <td>-0.195299</td>\n",
       "      <td>0.222833</td>\n",
       "      <td>-0.063875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294684</td>\n",
       "      <td>-0.051093</td>\n",
       "      <td>0.087507</td>\n",
       "      <td>0.167323</td>\n",
       "      <td>-0.025542</td>\n",
       "      <td>0.122528</td>\n",
       "      <td>-0.305256</td>\n",
       "      <td>-0.400959</td>\n",
       "      <td>0.060725</td>\n",
       "      <td>-0.201464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.206146</td>\n",
       "      <td>-0.189957</td>\n",
       "      <td>-0.070082</td>\n",
       "      <td>-0.139482</td>\n",
       "      <td>-0.012797</td>\n",
       "      <td>0.033483</td>\n",
       "      <td>-0.024374</td>\n",
       "      <td>0.050098</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>-0.209563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158793</td>\n",
       "      <td>-0.005378</td>\n",
       "      <td>0.255807</td>\n",
       "      <td>-0.155698</td>\n",
       "      <td>0.020708</td>\n",
       "      <td>0.069757</td>\n",
       "      <td>0.031914</td>\n",
       "      <td>0.221062</td>\n",
       "      <td>0.321345</td>\n",
       "      <td>-0.244561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.199385</td>\n",
       "      <td>-0.185504</td>\n",
       "      <td>-0.083854</td>\n",
       "      <td>-0.141421</td>\n",
       "      <td>-0.017199</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>-0.030184</td>\n",
       "      <td>0.061197</td>\n",
       "      <td>0.020538</td>\n",
       "      <td>-0.203361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157722</td>\n",
       "      <td>-0.014079</td>\n",
       "      <td>0.257975</td>\n",
       "      <td>-0.170310</td>\n",
       "      <td>0.032295</td>\n",
       "      <td>0.072032</td>\n",
       "      <td>0.034321</td>\n",
       "      <td>0.218060</td>\n",
       "      <td>0.324610</td>\n",
       "      <td>-0.250018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.325436</td>\n",
       "      <td>0.135226</td>\n",
       "      <td>0.279856</td>\n",
       "      <td>0.395852</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>-0.113369</td>\n",
       "      <td>-0.008104</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>-0.251575</td>\n",
       "      <td>0.430256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130794</td>\n",
       "      <td>0.142979</td>\n",
       "      <td>-0.289274</td>\n",
       "      <td>0.238762</td>\n",
       "      <td>-0.288147</td>\n",
       "      <td>-0.444972</td>\n",
       "      <td>0.570524</td>\n",
       "      <td>-0.380489</td>\n",
       "      <td>0.646494</td>\n",
       "      <td>0.040204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.362696</td>\n",
       "      <td>0.092874</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.083179</td>\n",
       "      <td>0.173212</td>\n",
       "      <td>0.104630</td>\n",
       "      <td>-0.027046</td>\n",
       "      <td>-0.062194</td>\n",
       "      <td>-0.207372</td>\n",
       "      <td>0.455595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057095</td>\n",
       "      <td>0.010565</td>\n",
       "      <td>-0.244574</td>\n",
       "      <td>-0.230967</td>\n",
       "      <td>-0.331063</td>\n",
       "      <td>-0.124080</td>\n",
       "      <td>0.519615</td>\n",
       "      <td>-0.360190</td>\n",
       "      <td>-0.290440</td>\n",
       "      <td>0.236591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.219362  0.169356 -0.325940  0.139796  0.186205 -0.171053  0.021949   \n",
       "1  0.206146 -0.189957 -0.070082 -0.139482 -0.012797  0.033483 -0.024374   \n",
       "2  0.199385 -0.185504 -0.083854 -0.141421 -0.017199  0.026786 -0.030184   \n",
       "3 -0.325436  0.135226  0.279856  0.395852  0.194274 -0.113369 -0.008104   \n",
       "4 -0.362696  0.092874  0.005255  0.083179  0.173212  0.104630 -0.027046   \n",
       "\n",
       "        7         8         9    ...       400       401       402       403  \\\n",
       "0 -0.195299  0.222833 -0.063875  ... -0.294684 -0.051093  0.087507  0.167323   \n",
       "1  0.050098  0.015184 -0.209563  ... -0.158793 -0.005378  0.255807 -0.155698   \n",
       "2  0.061197  0.020538 -0.203361  ... -0.157722 -0.014079  0.257975 -0.170310   \n",
       "3  0.002369 -0.251575  0.430256  ...  0.130794  0.142979 -0.289274  0.238762   \n",
       "4 -0.062194 -0.207372  0.455595  ...  0.057095  0.010565 -0.244574 -0.230967   \n",
       "\n",
       "        404       405       406       407       408       409  \n",
       "0 -0.025542  0.122528 -0.305256 -0.400959  0.060725 -0.201464  \n",
       "1  0.020708  0.069757  0.031914  0.221062  0.321345 -0.244561  \n",
       "2  0.032295  0.072032  0.034321  0.218060  0.324610 -0.250018  \n",
       "3 -0.288147 -0.444972  0.570524 -0.380489  0.646494  0.040204  \n",
       "4 -0.331063 -0.124080  0.519615 -0.360190 -0.290440  0.236591  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  <unk>\n",
       "1    <s>\n",
       "2   </s>\n",
       "3      .\n",
       "4      ,"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('embeddings_transformer_metadata.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2061, -0.1900, -0.0701, -0.1395, -0.0128,  0.0335, -0.0244,  0.0501,\n",
       "         0.0152, -0.2096,  0.1785,  0.1761,  0.1272, -0.0452, -0.2857,  0.1407,\n",
       "         0.1105,  0.0137, -0.0501, -0.3878, -0.0711,  0.2909,  0.2603,  0.0747,\n",
       "        -0.2745, -0.1565,  0.2664,  0.4928,  0.2273,  0.0009, -0.1338,  0.0137,\n",
       "        -0.2344, -0.1137, -0.1170,  0.0019, -0.1817, -0.1882, -0.0960,  0.1385,\n",
       "        -0.0960, -0.1383, -0.1745, -0.3204,  0.0648,  0.1075, -0.1242,  0.1911,\n",
       "         0.1702,  0.1536,  0.0584,  0.2445, -0.2514,  0.0175,  0.0533, -0.3792,\n",
       "        -0.0722,  0.3086,  0.1448, -0.1048,  0.1130,  0.0690, -0.0094, -0.0204,\n",
       "         0.0956, -0.1271,  0.0045, -0.0751, -0.0052, -0.0679,  0.0620, -0.2474,\n",
       "         0.0200, -0.1304,  0.3381, -0.0098, -0.0799, -0.0019, -0.1866, -0.1657,\n",
       "        -0.0246, -0.4796,  0.1132, -0.0148,  0.1152, -0.0615, -0.1035,  0.1069,\n",
       "        -0.1443, -0.1833, -0.1768, -0.1083, -0.3323, -0.0482,  0.3383,  0.0131,\n",
       "        -0.2484,  0.0700, -0.1408,  0.0017, -0.0363,  0.0833, -0.0521,  0.0148,\n",
       "         0.0483, -0.0601, -0.2692,  0.4280, -0.0562,  0.2522,  0.0806,  0.1821,\n",
       "        -0.1133,  0.1257,  0.0864,  0.1075, -0.3866, -0.4465,  0.0674,  0.1240,\n",
       "         0.2571,  0.2008, -0.0241,  0.0642,  0.1262,  0.3246, -0.0339,  0.0041,\n",
       "         0.1281,  0.0818,  0.1460,  0.0957, -0.1299, -0.0297,  0.2257,  0.0111,\n",
       "         0.0954, -0.0840,  0.0400, -0.1183,  0.2157,  0.0309, -0.1776,  0.2155,\n",
       "        -0.2740, -0.0105, -0.2705, -0.0192, -0.0192,  0.1151,  0.0529, -0.1871,\n",
       "        -0.0188,  0.1379, -0.1229, -0.1870,  0.1534, -0.1571, -0.0982, -0.0832,\n",
       "        -0.0565, -0.0661,  0.3503,  0.0438,  0.0751,  0.1459,  0.0458, -0.0965,\n",
       "         0.3747, -0.0364, -0.1465,  0.0953,  0.1431, -0.1914,  0.0242, -0.1490,\n",
       "         0.0384, -0.3503, -0.1368,  0.2842,  0.2370, -0.1061, -0.0815,  0.0233,\n",
       "        -0.0919, -0.0803, -0.4090,  0.0251, -0.2962, -0.0405, -0.0337, -0.0184,\n",
       "         0.0813,  0.0851,  0.1885,  0.0955, -0.0208, -0.0025, -0.1287,  0.0030,\n",
       "         0.0541,  0.0206,  0.1734,  0.0141, -0.0654, -0.1130, -0.2186, -0.1358,\n",
       "        -0.0887, -0.1348, -0.1635, -0.0432,  0.1133,  0.0034,  0.1136,  0.0891,\n",
       "        -0.0364,  0.1812, -0.0304,  0.0351,  0.0572, -0.0234,  0.0030, -0.1687,\n",
       "         0.0800,  0.0444, -0.0790, -0.1768, -0.0646, -0.2596,  0.2348,  0.2019,\n",
       "        -0.0090,  0.0767,  0.1083,  0.0294, -0.2187, -0.0861,  0.1489, -0.0528,\n",
       "         0.2480,  0.0369,  0.2627, -0.2971,  0.0341, -0.1967,  0.0658,  0.0321,\n",
       "        -0.1906,  0.1069,  0.1188, -0.2939,  0.2259,  0.0802, -0.0285, -0.0403,\n",
       "         0.2529,  0.3998,  0.0970,  0.0043,  0.0278,  0.1664,  0.0917,  0.1514,\n",
       "        -0.1111,  0.4146, -0.1718,  0.2398, -0.1019,  0.2070,  0.0057, -0.0494,\n",
       "         0.0773, -0.4457, -0.0614,  0.0503,  0.1197, -0.1258, -0.0921,  0.1257,\n",
       "        -0.3229, -0.1522,  0.0323, -0.0428,  0.0933,  0.3804,  0.0790, -0.0225,\n",
       "        -0.2125,  0.0807, -0.0616,  0.2489, -0.0049,  0.2001,  0.0942,  0.0400,\n",
       "         0.1248,  0.7928, -0.2469, -0.0829, -0.0646,  0.0266,  0.1091,  0.0644,\n",
       "        -0.0599, -0.2283, -0.0551, -0.2077, -0.4949, -0.1524, -0.0039,  0.0461,\n",
       "         0.0370,  0.1162,  0.1319,  0.1194, -0.2949,  0.0407,  0.0499,  0.1855,\n",
       "        -0.0922, -0.0428, -0.3781,  0.1747, -0.1301,  0.0758,  0.8726,  0.0722,\n",
       "         0.0949, -0.0579,  0.1307,  0.0764,  0.0049,  0.0747, -0.1876,  0.2526,\n",
       "        -0.0087,  0.3203,  0.1529,  0.1773, -0.0945, -0.1655,  0.1008,  0.2619,\n",
       "        -0.3512,  0.1379,  0.2051, -0.1441, -0.1870, -0.0749,  0.1483,  0.0736,\n",
       "         0.2480, -0.0079,  0.1719,  0.1829, -0.1409,  0.1199, -0.1101, -0.0096,\n",
       "         0.0597, -0.2939,  0.0696,  0.1318,  0.0615, -0.0417, -0.1025, -0.2083,\n",
       "        -0.0059,  0.1087, -0.0483,  0.0519, -0.0729, -0.2265, -0.1384, -0.1932,\n",
       "        -0.0148, -0.1047, -0.1422,  0.4154, -0.1707, -0.0291, -0.0415,  0.1417,\n",
       "         0.0201, -0.0456,  0.0909, -0.0740, -0.0235, -0.0133,  0.1839,  0.1287,\n",
       "         0.0510, -0.0180, -0.0890, -0.2862, -0.0739,  0.1063, -0.1037,  0.2602,\n",
       "        -0.1588, -0.0054,  0.2558, -0.1557,  0.0207,  0.0698,  0.0319,  0.2211,\n",
       "         0.3213, -0.2446], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
